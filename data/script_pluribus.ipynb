{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c1ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import io\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "829378c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hand(hand_text_block):\n",
    "    \"\"\"\n",
    "    Transforme le bloc de texte d'une main\n",
    "    en un dictionnaire Python propre.\n",
    "    \"\"\"\n",
    "    hand_data = {}\n",
    "\n",
    "    # S√©pare le bloc en lignes\n",
    "    for line in hand_text_block.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue # Ignore les lignes vides\n",
    "\n",
    "        # S√©pare la ligne en \"cl√© = valeur\"\n",
    "        if ' = ' in line:\n",
    "            # On s√©pare au premier '=' (au cas o√π une valeur contiendrait un '=')\n",
    "            key, value_str = line.split(' = ', 1)\n",
    "\n",
    "            # Nettoyage de la cl√©\n",
    "            key = key.strip()\n",
    "\n",
    "            # Nettoyage de la valeur (tr√®s important)\n",
    "            value_str = value_str.strip()\n",
    "            # Le fichier utilise 'true'/'false' (JS/JSON) au lieu de 'True'/'False' (Python)\n",
    "            value_str = value_str.replace('true', 'True')\n",
    "            value_str = value_str.replace('false', 'False')\n",
    "\n",
    "            # Tentative de conversion de la valeur en type Python\n",
    "            # (ex: \"[...]\" devient une liste, \"10000\" devient un int)\n",
    "            try:\n",
    "                value = ast.literal_eval(value_str)\n",
    "            except (ValueError, SyntaxError):\n",
    "                # Si ce n'est pas un type Python (ex: 'NT'), on garde la string\n",
    "                value = value_str.strip(\"'\") # Enl√®ve les guillemets superflus\n",
    "\n",
    "            hand_data[key] = value\n",
    "\n",
    "    return hand_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec07fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_action(action_str):\n",
    "    if action_str.startswith('d'): return None\n",
    "    parts = action_str.split(' ')\n",
    "    if len(parts) == 2:\n",
    "        if parts[1] == 'f': return {'player_id': parts[0], 'action_type': 'FOLD', 'amount': 0}\n",
    "        if parts[1] == 'cc': return {'player_id': parts[0], 'action_type': 'CALL_CHECK', 'amount': 0}\n",
    "    if len(parts) == 3:\n",
    "        if parts[1] == 'cbr':\n",
    "            try: return {'player_id': parts[0], 'action_type': 'BET_RAISE', 'amount': int(parts[2])}\n",
    "            except ValueError: return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a1395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: treys in /Users/killianguillaume/Desktop/RL_phase2/venv/lib/python3.10/site-packages (0.1.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install treys\n",
    "from treys import Evaluator, Card\n",
    "evaluator = Evaluator()\n",
    "\n",
    "# --- NOUVEAU : Outil 2 - Normalisateur Pr√©-flop ---\n",
    "RANKS = '23456789TJQKA'\n",
    "def get_hand_key(card1, card2):\n",
    "    r1, s1 = card1[0], card1[1]\n",
    "    r2, s2 = card2[0], card2[1]\n",
    "    rank_idx1 = RANKS.index(r1)\n",
    "    rank_idx2 = RANKS.index(r2)\n",
    "\n",
    "    if rank_idx1 > rank_idx2:\n",
    "        key = r1 + r2\n",
    "    else:\n",
    "        key = r2 + r1\n",
    "\n",
    "    if s1 == s2:\n",
    "        if r1 != r2: key += 's'\n",
    "    else:\n",
    "        key += 'o'\n",
    "    return key\n",
    "\n",
    "\n",
    "HAND_STRENGTH_MAP = {\n",
    "    \"High Card\": 0,\n",
    "    \"Pair\": 1,\n",
    "    \"Two Pair\": 2,\n",
    "    \"Three of a Kind\": 3,\n",
    "    \"Straight\": 4,\n",
    "    \"Flush\": 5,\n",
    "    \"Full House\": 6,\n",
    "    \"Four of a Kind\": 7,\n",
    "    \"Straight Flush\": 8\n",
    "}\n",
    "# --- NOUVEAU : Outil 3 - Dictionnaire d'√©quit√© Pr√©-flop ---\n",
    "# (La table de 169 mains que nous avons d√©finie)\n",
    "PREFLOP_EQUITY_6MAX = {\n",
    "    'AA': 0.648, 'KK': 0.613, 'QQ': 0.579, 'JJ': 0.546, 'TT': 0.514,\n",
    "    '99': 0.482, '88': 0.451, '77': 0.421, '66': 0.391, '55': 0.362,\n",
    "    '44': 0.334, '33': 0.306, '22': 0.279, 'AKs': 0.404, 'AQs': 0.383,\n",
    "    'AJs': 0.369, 'ATs': 0.358, 'A9s': 0.334, 'A8s': 0.323, 'A7s': 0.312,\n",
    "    'A6s': 0.300, 'A5s': 0.315, 'A4s': 0.304, 'A3s': 0.293, 'A2s': 0.283,\n",
    "    'KQs': 0.370, 'KJs': 0.355, 'KTs': 0.344, 'K9s': 0.320, 'K8s': 0.297,\n",
    "    'K7s': 0.286, 'K6s': 0.275, 'K5s': 0.264, 'K4s': 0.254, 'K3s': 0.244,\n",
    "    'K2s': 0.235, 'QJs': 0.341, 'QTs': 0.330, 'Q9s': 0.307, 'Q8s': 0.284,\n",
    "    'Q7s': 0.263, 'Q6s': 0.252, 'Q5s': 0.242, 'Q4s': 0.232, 'Q3s': 0.223,\n",
    "    'Q2s': 0.214, 'JTs': 0.317, 'J9s': 0.295, 'J8s': 0.272, 'J7s': 0.252,\n",
    "    'J6s': 0.232, 'J5s': 0.222, 'J4s': 0.212, 'J3s': 0.203, 'J2s': 0.195,\n",
    "    'T9s': 0.284, 'T8s': 0.262, 'T7s': 0.242, 'T6s': 0.222, 'T5s': 0.204,\n",
    "    'T4s': 0.194, 'T3s': 0.186, 'T2s': 0.178, '98s': 0.251, '97s': 0.232,\n",
    "    '96s': 0.212, '95s': 0.194, '94s': 0.177, '93s': 0.169, '92s': 0.162,\n",
    "    '87s': 0.222, '86s': 0.203, '85s': 0.185, '84s': 0.168, '83s': 0.152,\n",
    "    '82s': 0.144, '76s': 0.194, '75s': 0.177, '74s': 0.160, '73s': 0.144,\n",
    "    '72s': 0.137, '65s': 0.169, '64s': 0.152, '63s': 0.137, '62s': 0.130,\n",
    "    '54s': 0.145, '53s': 0.130, '52s': 0.123, '43s': 0.123, '42s': 0.116,\n",
    "    '32s': 0.109, 'AKo': 0.380, 'AQo': 0.358, 'AJo': 0.344, 'ATo': 0.332,\n",
    "    'A9o': 0.307, 'A8o': 0.295, 'A7o': 0.283, 'A6o': 0.270, 'A5o': 0.284,\n",
    "    'A4o': 0.272, 'A3o': 0.261, 'A2o': 0.250, 'KQo': 0.344, 'KJo': 0.329,\n",
    "    'KTo': 0.317, 'K9o': 0.291, 'K8o': 0.267, 'K7o': 0.255, 'K6o': 0.243,\n",
    "    'K5o': 0.231, 'K4o': 0.220, 'K3o': 0.210, 'K2o': 0.200, 'QJo': 0.314,\n",
    "    'QTo': 0.302, 'Q9o': 0.277, 'Q8o': 0.253, 'Q7o': 0.230, 'Q6o': 0.218,\n",
    "    'Q5o': 0.207, 'Q4o': 0.197, 'Q3o': 0.187, 'Q2o': 0.178, 'JTo': 0.288,\n",
    "    'J9o': 0.265, 'J8o': 0.241, 'J7o': 0.219, 'J6o': 0.198, 'J5o': 0.187,\n",
    "    'J4o': 0.177, 'J3o': 0.168, 'J2o': 0.159, 'T9o': 0.252, 'T8o': 0.229,\n",
    "    'T7o': 0.208, 'T6o': 0.187, 'T5o': 0.169, 'T4o': 0.159, 'T3o': 0.150,\n",
    "    'T2o': 0.142, '98o': 0.218, '97o': 0.198, '96o': 0.178, '95o': 0.160,\n",
    "    '94o': 0.143, '93o': 0.135, '92o': 0.127, '87o': 0.187, '86o': 0.168,\n",
    "    '85o': 0.150, '84o': 0.133, '83o': 0.117, '82o': 0.109, '76o': 0.159,\n",
    "    '75o': 0.142, '74o': 0.125, '73o': 0.109, '72o': 0.102, '65o': 0.133,\n",
    "    '64o': 0.117, '63o': 0.102, '62o': 0.095, '54o': 0.110, '53o': 0.095,\n",
    "    '52o': 0.088, '43o': 0.088, '42o': 0.081, '32o': 0.074\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70259220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_hand_block(hand_block_text):\n",
    "    \"\"\"\n",
    "    Prend un bloc de texte Pluribus et le \"d√©roule\",\n",
    "    retournant une liste de toutes les d√©cisions prises pendant cette main.\n",
    "    \"\"\"\n",
    "    decisions_in_this_hand = []\n",
    "\n",
    "    # 1. Analyser le bloc de texte de la main\n",
    "    parsed_data = parse_hand(hand_block_text)\n",
    "\n",
    "    # V√©rification : si le parsing √©choue ou manque de cl√©s, on sort\n",
    "    if 'players' not in parsed_data or 'starting_stacks' not in parsed_data or 'actions' not in parsed_data:\n",
    "        # print(\"Bloc de main corrompu, ignor√©.\")\n",
    "        return []\n",
    "\n",
    "    # 2. Initialiser l'√©tat\n",
    "\n",
    "\n",
    "\n",
    "    player_names = parsed_data['players']\n",
    "    POSITION_NAMES_6MAX = [\"SB\", \"BB\", \"UTG\", \"MP\", \"CO\", \"BTN\"]\n",
    "    player_position_map = {name: pos for name, pos in zip(player_names, POSITION_NAMES_6MAX)}\n",
    "    position_player_map = {pos: name for name, pos in player_position_map.items()}\n",
    "    current_stacks = {name: stack for name, stack in zip(player_names, parsed_data['starting_stacks'])}\n",
    "    player_id_map = {f'p{i+1}': name for i, name in enumerate(player_names)}\n",
    "    current_bets = {name: 0 for name in player_names}\n",
    "    players_in_hand = set(player_names)\n",
    "    pot_size, street, board_cards_treys = 0, 'preflop', []\n",
    "    hole_cards_dict = {name: [] for name in player_names}\n",
    "    treys_hole_cards = {name: [] for name in player_names}\n",
    "    player_features = {name: {} for name in player_names}\n",
    "    board_features = {\n",
    "        'board_is_paired': 0,\n",
    "        'board_is_monotone': 0,\n",
    "        'board_connectedness': 0\n",
    "      }\n",
    "    # 3. G√©rer les Blinds\n",
    "    sb_amount = parsed_data['blinds_or_straddles'][0]\n",
    "    bb_amount = parsed_data['blinds_or_straddles'][1]\n",
    "    sb_player = player_names[0]\n",
    "    bb_player = player_names[1]\n",
    "    current_stacks[sb_player] -= sb_amount\n",
    "    current_bets[sb_player] = sb_amount\n",
    "    current_stacks[bb_player] -= bb_amount\n",
    "    current_bets[bb_player] = bb_amount\n",
    "    pot_size = sb_amount + bb_amount\n",
    "\n",
    "    # 4. Boucle d'action\n",
    "    for action_str in parsed_data['actions']:\n",
    "        if action_str.startswith('d'):\n",
    "            parts = action_str.split(' ')\n",
    "            if parts[1] == 'dh': # Cartes priv√©es\n",
    "                player_id, cards_str = parts[2], parts[3]\n",
    "                player_name = player_id_map.get(player_id)\n",
    "                if player_name:\n",
    "                    cards = [cards_str[i:i+2] for i in range(0, len(cards_str), 2)]\n",
    "                    hole_cards_dict[player_name] = cards\n",
    "                    treys_hole_cards[player_name] = [Card.new(c) for c in cards]\n",
    "                    key = get_hand_key(cards[0], cards[1])\n",
    "                    equity = PREFLOP_EQUITY_6MAX.get(key, 0.0)\n",
    "                    player_features[player_name]['preflop_equity'] = equity\n",
    "                    player_features[player_name]['hand_strength_rank'] = HAND_STRENGTH_MAP.get(\"Pair\", 0) if cards[0][0] == cards[1][0] else HAND_STRENGTH_MAP.get(\"High Card\", 0)\n",
    "\n",
    "            elif parts[1] == 'db': # Cartes du board\n",
    "                new_cards_str = parts[2]\n",
    "                new_cards_list = [new_cards_str[i:i+2] for i in range(0, len(new_cards_str), 2)]\n",
    "                board_cards_treys.extend([Card.new(c) for c in new_cards_list])\n",
    "\n",
    "                if len(board_cards_treys) == 3: street = 'flop'\n",
    "                elif len(board_cards_treys) == 4: street = 'turn'\n",
    "                elif len(board_cards_treys) == 5: street = 'river'\n",
    "                current_bets = {name: 0 for name in player_names}\n",
    "\n",
    "                board_ranks = sorted([Card.get_rank_int(c) for c in board_cards_treys])\n",
    "                board_suits = [Card.get_suit_int(c) for c in board_cards_treys]\n",
    "                # 1. Paire sur le board ?\n",
    "                board_features['board_is_paired'] = 1 if len(set(board_ranks)) < len(board_ranks) else 0\n",
    "\n",
    "                # 2. Board monochrome ? (Uniquement au flop)\n",
    "                if street == 'flop':\n",
    "                    board_features['board_is_monotone'] = 1 if len(set(board_suits)) == 1 else 0\n",
    "\n",
    "                # 3. Connectivit√© du board\n",
    "                if len(board_ranks) >= 3:\n",
    "                    gaps = [board_ranks[i+1] - board_ranks[i] for i in range(len(board_ranks) - 1)]\n",
    "                    # 3 = \"3-straight\" (ex: 7-8-9), 2 = \"2-gap\" (ex: 7-9-J), 1 = \"1-gap\" (ex: 7-8-T)\n",
    "                    board_features['board_connectedness'] = sum(1 for gap in gaps if gap == 1)\n",
    "                    # --- MISE √Ä JOUR DE LA FORCE + TIRAGES POUR CHAQUE JOUEUR ---\n",
    "                for name in players_in_hand:\n",
    "                    if treys_hole_cards[name]:\n",
    "                        all_cards = treys_hole_cards[name] + board_cards_treys\n",
    "                        all_ranks = sorted([Card.get_rank_int(c) for c in all_cards], reverse=True)\n",
    "                        all_suits = [Card.get_suit_int(c) for c in all_cards]\n",
    "\n",
    "                        # A. Mettre √† jour la force (comme avant)\n",
    "                        rank = evaluator.evaluate(treys_hole_cards[name], board_cards_treys)\n",
    "                        rank_class = evaluator.get_rank_class(rank)\n",
    "                        class_str = evaluator.class_to_string(rank_class)\n",
    "                        player_features[name]['hand_strength_rank'] = HAND_STRENGTH_MAP.get(class_str, 0)\n",
    "\n",
    "                        # B. Mettre √† jour les tirages (uniquement Flop/Turn)\n",
    "                        if street != 'river':\n",
    "                            # B1. Tirage Couleur ?\n",
    "                            suit_counts = [all_suits.count(s) for s in range(1, 5)]\n",
    "                            player_features[name]['has_flush_draw'] = 1 if (4 in suit_counts) else 0\n",
    "\n",
    "                            # B2. Tirage Quinte ? (Simplifi√©: 4 rangs uniques cons√©cutifs ou avec un trou)\n",
    "                            unique_ranks = sorted(list(set(all_ranks)))\n",
    "                            player_features[name]['has_straight_draw'] = 0\n",
    "                            if len(unique_ranks) >= 4:\n",
    "                                for i in range(len(unique_ranks) - 3):\n",
    "                                    # V√©rifie un \"OESD\" (Open-Ended) ex: 5,6,7,8\n",
    "                                    if unique_ranks[i+3] - unique_ranks[i] == 3:\n",
    "                                        player_features[name]['has_straight_draw'] = 1\n",
    "                                        break\n",
    "                                    # V√©rifie un \"Gutshot\" ex: 5,6,8,9\n",
    "                                    if i < len(unique_ranks) - 4 and unique_ranks[i+4] - unique_ranks[i] == 4:\n",
    "                                        player_features[name]['has_straight_draw'] = 1\n",
    "                                        break\n",
    "\n",
    "        else:\n",
    "            parsed_action = parse_action(action_str)\n",
    "            if parsed_action:\n",
    "                player_id = parsed_action['player_id']\n",
    "                player_name = player_id_map.get(player_id)\n",
    "                if not player_name or player_name not in players_in_hand: continue\n",
    "\n",
    "                max_bet = max(current_bets.values())\n",
    "                amount_to_call = max_bet - current_bets[player_name]\n",
    "\n",
    "                features = {\n",
    "                    'hand_id': parsed_data['hand'],\n",
    "                    'street': street,\n",
    "                    'stack_before': current_stacks[player_name],\n",
    "                    'pot_size_before': pot_size,\n",
    "                    'amount_to_call': amount_to_call,\n",
    "                    'players_in_hand': len(players_in_hand),\n",
    "                    'hole_cards': hole_cards_dict[player_name],\n",
    "                    'board_cards': [Card.int_to_str(c) for c in board_cards_treys],\n",
    "                    'preflop_equity': player_features[player_name].get('preflop_equity', 0.0),\n",
    "                    'hand_strength_rank': player_features[player_name].get('hand_strength_rank', 0),\n",
    "                    'has_flush_draw': player_features[player_name].get('has_flush_draw', 0),\n",
    "                    'has_straight_draw': player_features[player_name].get('has_straight_draw', 0),\n",
    "                    'board_is_paired': board_features['board_is_paired'],\n",
    "                    'board_is_monotone': board_features['board_is_monotone'],\n",
    "                    'board_connectedness': board_features['board_connectedness']\n",
    "                }\n",
    "                for pos in POSITION_NAMES_6MAX:\n",
    "                    player_name_at_pos = position_player_map.get(pos)\n",
    "\n",
    "                    if player_name_at_pos:\n",
    "                        # Un joueur est assis √† ce si√®ge\n",
    "                        features[f'pos_{pos}_stack'] = current_stacks[player_name_at_pos]\n",
    "                        features[f'pos_{pos}_in_hand'] = 1 if player_name_at_pos in players_in_hand else 0\n",
    "                        features[f'pos_{pos}_invested'] = current_bets[player_name_at_pos]\n",
    "                    else:\n",
    "                        # Le si√®ge est vide (ex: jeu √† 5)\n",
    "                        features[f'pos_{pos}_stack'] = 0\n",
    "                        features[f'pos_{pos}_in_hand'] = 0\n",
    "                        features[f'pos_{pos}_invested'] = 0\n",
    "\n",
    "                action_type, total_bet_amount = parsed_action['action_type'], parsed_action['amount']\n",
    "                target_action, invested_this_action = 'UNKNOWN', 0\n",
    "                if action_type == 'FOLD':\n",
    "                    target_action = 'FOLD'\n",
    "                    players_in_hand.remove(player_name)\n",
    "                elif action_type == 'CALL_CHECK':\n",
    "                    target_action = 'CALL' if amount_to_call > 0 else 'CHECK'\n",
    "                    invested_this_action = amount_to_call\n",
    "                elif action_type == 'BET_RAISE':\n",
    "                    invested_this_action = total_bet_amount - current_bets[player_name]\n",
    "                    target_action = 'RAISE' if amount_to_call > 0 else 'BET'\n",
    "\n",
    "                current_stacks[player_name] -= invested_this_action\n",
    "                current_bets[player_name] += invested_this_action\n",
    "                pot_size += invested_this_action\n",
    "\n",
    "                features['target_action'] = target_action\n",
    "                features['target_amount_invested'] = invested_this_action # On le garde pour l'instant\n",
    "                decisions_in_this_hand.append(features)\n",
    "\n",
    "    return decisions_in_this_hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85830f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D√©marrage de la lecture du ZIP...\n"
     ]
    }
   ],
   "source": [
    "phh_zip = \"poker-hand-histories.zip\" # Votre fichier Pluribus de 1.9GB\n",
    "delimiteur_de_main = \"variant = 'NT'\"\n",
    "mains_lues = 0\n",
    "\n",
    "all_decisions = [] # La liste finale de TOUTES les d√©cisions\n",
    "\n",
    "print(\"D√©marrage de la lecture du ZIP...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7f8f95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyse termin√©e ---\n",
      "Total des mains lues et pars√©es : 10011\n",
      "D√©roulage termin√©. 91444 d√©cisions cr√©√©es.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with zipfile.ZipFile(phh_zip, 'r') as zf:\n",
    "        for nom_fichier_interne in zf.namelist():\n",
    "            if not nom_fichier_interne.endswith('.phh'):\n",
    "                continue\n",
    "\n",
    "            # print(f\"Lecture de {nom_fichier_interne}...\")\n",
    "            with zf.open(nom_fichier_interne, 'r') as f_binaire:\n",
    "                f_texte = io.TextIOWrapper(f_binaire, encoding='utf-8')\n",
    "                main_actuelle_buffer = []\n",
    "\n",
    "                for line in f_texte:\n",
    "                    cleaned_line = line.strip()\n",
    "\n",
    "                    if cleaned_line.startswith(delimiteur_de_main) and main_actuelle_buffer:\n",
    "                        # 1. Traiter la main pr√©c√©dente\n",
    "                        try:\n",
    "                            hand_block = \"\".join(main_actuelle_buffer)\n",
    "                            decisions = unroll_hand_block(hand_block)\n",
    "                            if decisions:\n",
    "                                all_decisions.extend(decisions)\n",
    "                                mains_lues += 1\n",
    "                        except Exception as e:\n",
    "                            # Cette exception est maintenant beaucoup plus petite et plus s√ªre\n",
    "                            print(f\"ERREUR Critique lors du d√©roulage, main ignor√©e : {e}\")\n",
    "\n",
    "                        # 2. R√©initialiser le buffer pour la nouvelle main\n",
    "                        main_actuelle_buffer = [line]\n",
    "\n",
    "                    elif cleaned_line.startswith(delimiteur_de_main):\n",
    "                        main_actuelle_buffer = [line]\n",
    "                    elif main_actuelle_buffer:\n",
    "                        main_actuelle_buffer.append(line)\n",
    "\n",
    "                # --- CORRECTION DE LA DERNI√àRE MAIN ---\n",
    "                # Traiter la TOUTE DERNI√àRE main du fichier\n",
    "                if main_actuelle_buffer:\n",
    "                    try:\n",
    "                        hand_block = \"\".join(main_actuelle_buffer)\n",
    "                        decisions = unroll_hand_block(hand_block)\n",
    "                        if decisions:\n",
    "                            all_decisions.extend(decisions)\n",
    "                            mains_lues += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"ERREUR Critique lors du d√©roulage, DERNI√àRE main ignor√©e : {e}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erreur : Le fichier '{phh_zip}' n'a pas √©t√© trouv√©.\")\n",
    "except Exception as e:\n",
    "    print(f\"Une erreur g√©n√©rale est survenue : {e}\")\n",
    "\n",
    "print(\"\\n--- Analyse termin√©e ---\")\n",
    "print(f\"Total des mains lues et pars√©es : {mains_lues}\")\n",
    "print(f\"D√©roulage termin√©. {len(all_decisions)} d√©cisions cr√©√©es.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aa08556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame 'Pluribus Am√©lior√©' cr√©√© !\n",
      "\n",
      "--- 5 premi√®res lignes (.head()) ---\n",
      "   hand_id   street  stack_before  pot_size_before  amount_to_call  \\\n",
      "0        0  preflop         10000              150             100   \n",
      "1        0  preflop         10000              150             100   \n",
      "2        0  preflop         10000              360             210   \n",
      "3        0  preflop         10000              360             210   \n",
      "4        0  preflop          9950              360             160   \n",
      "\n",
      "   players_in_hand hole_cards board_cards  preflop_equity  hand_strength_rank  \\\n",
      "0                6   [9c, 3d]          []           0.135                   0   \n",
      "1                5   [Ah, 4h]          []           0.304                   0   \n",
      "2                5   [Th, 5s]          []           0.169                   0   \n",
      "3                4   [6c, 7s]          []           0.159                   0   \n",
      "4                3   [Tc, Qc]          []           0.330                   0   \n",
      "\n",
      "   ...  pos_MP_in_hand  pos_MP_invested  pos_CO_stack  pos_CO_in_hand  \\\n",
      "0  ...               1                0         10000               1   \n",
      "1  ...               1                0         10000               1   \n",
      "2  ...               1              210         10000               1   \n",
      "3  ...               1              210         10000               0   \n",
      "4  ...               1              210         10000               0   \n",
      "\n",
      "   pos_CO_invested  pos_BTN_stack  pos_BTN_in_hand  pos_BTN_invested  \\\n",
      "0                0          10000                1                 0   \n",
      "1                0          10000                1                 0   \n",
      "2                0          10000                1                 0   \n",
      "3                0          10000                1                 0   \n",
      "4                0          10000                0                 0   \n",
      "\n",
      "   target_action  target_amount_invested  \n",
      "0           FOLD                       0  \n",
      "1          RAISE                     210  \n",
      "2           FOLD                       0  \n",
      "3           FOLD                       0  \n",
      "4           CALL                     160  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "\n",
      "--- V√©rification des nouvelles colonnes ---\n",
      "\n",
      "√âquit√© Pr√©-flop (preflop_equity):\n",
      "count    91444.000000\n",
      "mean         0.209667\n",
      "std          0.104214\n",
      "min          0.000000\n",
      "25%          0.142000\n",
      "50%          0.219000\n",
      "75%          0.291000\n",
      "max          0.404000\n",
      "Name: preflop_equity, dtype: float64\n",
      "\n",
      "Force de la Main (hand_strength_rank):\n",
      "hand_strength_rank\n",
      "High Card          67047\n",
      "Pair               17792\n",
      "Two Pair            3907\n",
      "Three of a Kind     1245\n",
      "Straight             515\n",
      "Flush                482\n",
      "Full House           413\n",
      "Four of a Kind        40\n",
      "Straight Flush         3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if all_decisions:\n",
    "    ml_df = pd.DataFrame(all_decisions)\n",
    "    print(\"\\nDataFrame 'Pluribus Am√©lior√©' cr√©√© !\")\n",
    "\n",
    "    print(\"\\n--- 5 premi√®res lignes (.head()) ---\")\n",
    "    print(ml_df.head())\n",
    "\n",
    "    print(\"\\n--- V√©rification des nouvelles colonnes ---\")\n",
    "    print(\"\\n√âquit√© Pr√©-flop (preflop_equity):\")\n",
    "    print(ml_df['preflop_equity'].describe())\n",
    "\n",
    "    print(\"\\nForce de la Main (hand_strength_rank):\")\n",
    "    print(ml_df['hand_strength_rank'].map({v: k for k, v in HAND_STRENGTH_MAP.items()}).value_counts(dropna=False))\n",
    "else:\n",
    "    print(\"\\nERREUR : Aucune donn√©e n'a √©t√© cr√©√©e. V√©rifiez votre fichier ZIP et les d√©limiteurs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f4f53b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hand_id': 0,\n",
       " 'street': 'preflop',\n",
       " 'stack_before': 10000,\n",
       " 'pot_size_before': 150,\n",
       " 'amount_to_call': 100,\n",
       " 'players_in_hand': 6,\n",
       " 'hole_cards': ['9c', '3d'],\n",
       " 'board_cards': [],\n",
       " 'preflop_equity': 0.135,\n",
       " 'hand_strength_rank': 0,\n",
       " 'has_flush_draw': 0,\n",
       " 'has_straight_draw': 0,\n",
       " 'board_is_paired': 0,\n",
       " 'board_is_monotone': 0,\n",
       " 'board_connectedness': 0,\n",
       " 'pos_SB_stack': 9950,\n",
       " 'pos_SB_in_hand': 1,\n",
       " 'pos_SB_invested': 50,\n",
       " 'pos_BB_stack': 9900,\n",
       " 'pos_BB_in_hand': 1,\n",
       " 'pos_BB_invested': 100,\n",
       " 'pos_UTG_stack': 10000,\n",
       " 'pos_UTG_in_hand': 1,\n",
       " 'pos_UTG_invested': 0,\n",
       " 'pos_MP_stack': 10000,\n",
       " 'pos_MP_in_hand': 1,\n",
       " 'pos_MP_invested': 0,\n",
       " 'pos_CO_stack': 10000,\n",
       " 'pos_CO_in_hand': 1,\n",
       " 'pos_CO_invested': 0,\n",
       " 'pos_BTN_stack': 10000,\n",
       " 'pos_BTN_in_hand': 1,\n",
       " 'pos_BTN_invested': 0,\n",
       " 'target_action': 'FOLD',\n",
       " 'target_amount_invested': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_df.iloc[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4366540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossier ajout√© au path : /Users/killianguillaume/Desktop/RL_phase2\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "root_dir = current_dir.parent\n",
    "if str(root_dir) not in sys.path:\n",
    "    sys.path.append(str(root_dir))\n",
    "print(f\"Dossier ajout√© au path : {root_dir}\")\n",
    "# sys.path.append(str(Path(__file__).parent.parent))\n",
    "\n",
    "from core.game_state import GameState\n",
    "from features.feature_builder import FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce84bd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tous les tests pass√©s !\n"
     ]
    }
   ],
   "source": [
    "def infer_blinds_from_row(row) -> tuple[int, int]:\n",
    "    \"\"\"\n",
    "    D√©duire (small_blind, big_blind) depuis une ligne Pluribus\n",
    "    \n",
    "    Strat√©gie:\n",
    "    1. Si preflop ET pos_BB_invested est \"simple\" ‚Üí c'est la BB\n",
    "    2. Sinon, chercher dans les autres colonnes (pos_SB_invested, etc.)\n",
    "    3. Fallback: 50/100\n",
    "    \n",
    "    Args:\n",
    "        row: pd.Series d'une ligne Pluribus\n",
    "    \n",
    "    Returns:\n",
    "        (small_blind, big_blind)\n",
    "    \"\"\"\n",
    "    \n",
    "    # === M√©thode 1: Depuis pos_BB_invested (preflop uniquement) ===\n",
    "    if row['street'] == 'preflop':\n",
    "        bb_invested = row.get('pos_BB_invested', 0)\n",
    "        \n",
    "        # Si BB n'a fait aucune action (juste post√© la blind)\n",
    "        # Heuristique: bb_invested doit √™tre un multiple de 50\n",
    "        if bb_invested > 0 and bb_invested <= 1000 and bb_invested % 50 == 0:\n",
    "            big_blind = bb_invested\n",
    "            small_blind = big_blind // 2\n",
    "            return small_blind, big_blind\n",
    "    \n",
    "    # === M√©thode 2: Depuis pos_SB_invested ===\n",
    "    if 'pos_SB_invested' in row:\n",
    "        sb_invested = row['pos_SB_invested']\n",
    "        if sb_invested > 0 and sb_invested <= 500 and sb_invested % 25 == 0:\n",
    "            small_blind = sb_invested\n",
    "            big_blind = small_blind * 2\n",
    "            return small_blind, big_blind\n",
    "    \n",
    "    # === M√©thode 3: D√©duire depuis amount_to_call ===\n",
    "    # Si un joueur doit call la BB, amount_to_call ‚âà BB\n",
    "    if row['street'] == 'preflop' and row['amount_to_call'] > 0:\n",
    "        call_amount = row['amount_to_call']\n",
    "        \n",
    "        # Arrondir au multiple de 50 le plus proche\n",
    "        big_blind = round(call_amount / 50) * 50\n",
    "        if big_blind > 0:\n",
    "            small_blind = big_blind // 2\n",
    "            return small_blind, big_blind\n",
    "    \n",
    "    # === Fallback: Valeurs par d√©faut ===\n",
    "    return 50, 100\n",
    "\n",
    "\n",
    "# === Test unitaire ===\n",
    "def test_infer_blinds():\n",
    "    \"\"\"Tests de la fonction\"\"\"\n",
    "    \n",
    "    # Test 1: Preflop standard\n",
    "    row1 = pd.Series({\n",
    "        'street': 'preflop',\n",
    "        'pos_BB_invested': 100,\n",
    "        'amount_to_call': 100\n",
    "    })\n",
    "    assert infer_blinds_from_row(row1) == (50, 100)\n",
    "    \n",
    "    # Test 2: Niveau sup√©rieur\n",
    "    row2 = pd.Series({\n",
    "        'street': 'preflop',\n",
    "        'pos_BB_invested': 400,\n",
    "        'amount_to_call': 400\n",
    "    })\n",
    "    assert infer_blinds_from_row(row2) == (200, 400)\n",
    "    \n",
    "    # Test 3: Postflop (fallback)\n",
    "    row3 = pd.Series({\n",
    "        'street': 'flop',\n",
    "        'pos_BB_invested': 5000,\n",
    "        'amount_to_call': 0\n",
    "    })\n",
    "    assert infer_blinds_from_row(row3) == (50, 100)\n",
    "    \n",
    "    print(\"‚úÖ Tous les tests pass√©s !\")\n",
    "\n",
    "# Lance le test\n",
    "test_infer_blinds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "765f1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def infer_player_position(row):\n",
    "    \"\"\"\n",
    "    D√©duire la position du joueur d√©cisionnaire\n",
    "    \n",
    "    Logique: Le joueur d√©cisionnaire est celui dont le stack\n",
    "             correspond √† stack_before\n",
    "    \"\"\"\n",
    "    stack_before = row['stack_before']\n",
    "    \n",
    "    for pos in ['SB', 'BB', 'UTG', 'MP', 'CO', 'BTN']:\n",
    "        col_stack = f'pos_{pos}_stack'\n",
    "        col_in_hand = f'pos_{pos}_in_hand'\n",
    "        \n",
    "        if col_stack in row and col_in_hand in row:\n",
    "            if row[col_in_hand] == 1 and row[col_stack] == stack_before:\n",
    "                return pos\n",
    "    \n",
    "    # Fallback: si pas trouv√©, retourner BTN\n",
    "    return 'BTN'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "596aa3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_opponent_stacks(row, hero_position):\n",
    "    \"\"\"\n",
    "    Extraire les stacks des adversaires actifs\n",
    "    \"\"\"\n",
    "    stacks = []\n",
    "    \n",
    "    for pos in ['SB', 'BB', 'UTG', 'MP', 'CO', 'BTN']:\n",
    "        # Exclure le hero\n",
    "        if pos == hero_position:\n",
    "            continue\n",
    "        \n",
    "        col_stack = f'pos_{pos}_stack'\n",
    "        col_in_hand = f'pos_{pos}_in_hand'\n",
    "        \n",
    "        if col_stack in row and col_in_hand in row:\n",
    "            if row[col_in_hand] == 1:\n",
    "                stacks.append(row[col_stack])\n",
    "    \n",
    "    return stacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d7d036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pot_odds(amount_to_call, pot_size):\n",
    "    \"\"\"Calculer les pot odds\"\"\"\n",
    "    if amount_to_call == 0:\n",
    "        return 0.0\n",
    "    return amount_to_call / (pot_size + amount_to_call)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8002bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pluribus_row_to_gamestate(row):\n",
    "    \"\"\"\n",
    "    Convertir une ligne Pluribus ‚Üí GameState (compatible avec FeatureExtractor)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Identifier la position du joueur\n",
    "    position = infer_player_position(row)\n",
    "    \n",
    "    # 2. Extraire les stacks adverses\n",
    "    opponent_stacks = extract_opponent_stacks(row, position)\n",
    "    small_blind, big_blind = infer_blinds_from_row(row)\n",
    "    \n",
    "    # 4. Calculer pot odds\n",
    "    pot_odds = calculate_pot_odds(row['amount_to_call'], row['pot_size_before'])\n",
    "    \n",
    "    # 5. Actions l√©gales (d√©duites de target_action)\n",
    "    # Par d√©faut: fold, call toujours possibles\n",
    "    legal_actions = ['fold', 'call']\n",
    "    \n",
    "    # Si on peut raise (stack suffisant)\n",
    "    if row['stack_before'] > row['amount_to_call']:\n",
    "        legal_actions.append('raise')\n",
    "    'opponent_stacks'\n",
    "    # 6. Construire le GameState\n",
    "    gamestate = GameState(\n",
    "        hole_cards=row['hole_cards'],\n",
    "        board=row['board_cards'] if len(row['board_cards']) > 0 else [],\n",
    "        street=row['street'],\n",
    "        position=position,\n",
    "        num_active_players=row['players_in_hand'],\n",
    "        pot_size=row['pot_size_before'],\n",
    "        stack=row['stack_before'],\n",
    "        big_blind=big_blind,  # Assum√© depuis les exemples\n",
    "        small_blind=small_blind,\n",
    "        amount_to_call=row['amount_to_call'],\n",
    "        legal_actions=legal_actions,\n",
    "        actions_this_street=[],  # Pas dispo dans Pluribus DF\n",
    "        player_id=None,\n",
    "    )\n",
    "    \n",
    "    return gamestate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "859ba5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_MAPPING = {\n",
    "    'FOLD': 0,\n",
    "    'CALL': 1,\n",
    "    'CHECK': 1,   # ‚úÖ CHECK = CALL avec montant 0\n",
    "    'RAISE': 2,\n",
    "    'BET': 2,     # ‚úÖ BET = RAISE (premier √† miser)\n",
    "    'ALL_IN': 2   # ‚úÖ ALL-IN = RAISE (cas extr√™me)\n",
    "}\n",
    "\n",
    "\n",
    "def map_action_to_label(action: str) -> int:\n",
    "    \"\"\"\n",
    "    Mapper une action Pluribus ‚Üí label (0, 1, 2)\n",
    "    \n",
    "    Raises:\n",
    "        KeyError si action inconnue\n",
    "    \"\"\"\n",
    "    action_upper = action.upper().strip()\n",
    "    \n",
    "    if action_upper not in ACTION_MAPPING:\n",
    "        raise KeyError(f\"Action inconnue: '{action}' (actions valides: {list(ACTION_MAPPING.keys())})\")\n",
    "    \n",
    "    return ACTION_MAPPING[action_upper]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a3fc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_pluribus_df(df, output_path, max_rows=None):\n",
    "    \"\"\"\n",
    "    Convertir le DataFrame Pluribus en features (44 dims)\n",
    "    \n",
    "    Args:\n",
    "        df_path: Chemin vers le DataFrame Pluribus (.parquet ou .csv)\n",
    "        output_path: Chemin de sortie (.npz)\n",
    "        max_rows: Limiter le nombre de lignes (pour test)\n",
    "    \n",
    "    Returns:\n",
    "        X: (N, 44) features\n",
    "        y: (N,) labels (0=FOLD, 1=CALL, 2=RAISE)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Charger le DataFrame\n",
    "    # print(f\"Chargement de {df_path}...\")\n",
    "    \n",
    "    # if df_path.endswith('.parquet'):\n",
    "    #     df = pd.read_parquet(df_path)\n",
    "    # else:\n",
    "    #     df = pd.read_csv(df_path)\n",
    "    \n",
    "    if max_rows:\n",
    "        df = df.head(max_rows)\n",
    "        print(f\"‚ö†Ô∏è  Limitation √† {max_rows} lignes pour test\")\n",
    "    \n",
    "    print(f\"‚úÖ DataFrame charg√©: {len(df)} lignes, {len(df.columns)} colonnes\")\n",
    "    \n",
    "    # Initialiser l'extracteur\n",
    "    extractor = FeatureExtractor()\n",
    "    \n",
    "    # Convertir chaque ligne\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    errors = []\n",
    "    \n",
    "    print(\"\\nüîÑ Conversion en cours...\")\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            # 1. Convertir en GameState\n",
    "            gamestate = pluribus_row_to_gamestate(row)\n",
    "            \n",
    "            # 2. Extraire les 44 features\n",
    "            features = extractor.extract(gamestate)\n",
    "            \n",
    "            label = map_action_to_label(row['target_action'])\n",
    "            \n",
    "            X_list.append(features)\n",
    "            y_list.append(label)\n",
    "            \n",
    "            if (idx + 1) % 10000 == 0:\n",
    "                print(f\"   {idx + 1:,}/{len(df):,} lignes trait√©es...\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            errors.append((idx, str(e)))\n",
    "            if len(errors) <= 5:  # Afficher les 5 premi√®res erreurs\n",
    "                print(f\"‚ö†Ô∏è  Erreur ligne {idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Convertir en numpy\n",
    "    X = np.array(X_list, dtype=np.float32)\n",
    "    y = np.array(y_list, dtype=np.int32)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Conversion termin√©e!\")\n",
    "    print(f\"   ‚úì Lignes converties: {len(X):,}/{len(df):,}\")\n",
    "    print(f\"   ‚úì X shape: {X.shape}\")\n",
    "    print(f\"   ‚úì y shape: {y.shape}\")\n",
    "    print(f\"   ‚úì Erreurs: {len(errors)}\")\n",
    "    \n",
    "    # Distribution des labels\n",
    "    label_counts = np.bincount(y)\n",
    "    print(f\"\\nüìä Distribution des actions:\")\n",
    "    print(f\"   FOLD:  {label_counts[0]:,} ({label_counts[0]/len(y)*100:.1f}%)\")\n",
    "    print(f\"   CALL:  {label_counts[1]:,} ({label_counts[1]/len(y)*100:.1f}%)\")\n",
    "    print(f\"   RAISE: {label_counts[2]:,} ({label_counts[2]/len(y)*100:.1f}%)\")\n",
    "    \n",
    "    # Sauvegarder\n",
    "    print(f\"\\nüíæ Sauvegarde dans {output_path}...\")\n",
    "    np.savez_compressed(output_path, X=X, y=y)\n",
    "    print(f\"‚úÖ Fichier sauvegard√© ({Path(output_path).stat().st_size / 1024 / 1024:.1f} MB)\")\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fc992f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Input: pluribus_processed.parquet\n",
      "üìÇ Output: pluribus_features.npz\n",
      "‚úÖ DataFrame charg√©: 91444 lignes, 35 colonnes\n",
      "\n",
      "üîÑ Conversion en cours...\n",
      "   10,000/91,444 lignes trait√©es...\n",
      "   20,000/91,444 lignes trait√©es...\n",
      "   30,000/91,444 lignes trait√©es...\n",
      "   40,000/91,444 lignes trait√©es...\n",
      "   50,000/91,444 lignes trait√©es...\n",
      "   60,000/91,444 lignes trait√©es...\n",
      "   70,000/91,444 lignes trait√©es...\n",
      "   80,000/91,444 lignes trait√©es...\n",
      "   90,000/91,444 lignes trait√©es...\n",
      "\n",
      "‚úÖ Conversion termin√©e!\n",
      "   ‚úì Lignes converties: 91,444/91,444\n",
      "   ‚úì X shape: (91444, 87)\n",
      "   ‚úì y shape: (91444,)\n",
      "   ‚úì Erreurs: 0\n",
      "\n",
      "üìä Distribution des actions:\n",
      "   FOLD:  48,313 (52.8%)\n",
      "   CALL:  24,635 (26.9%)\n",
      "   RAISE: 18,496 (20.2%)\n",
      "\n",
      "üíæ Sauvegarde dans pluribus_features.npz...\n",
      "‚úÖ Fichier sauvegard√© (2.1 MB)\n",
      "\n",
      "üéâ Conversion termin√©e (Simulation)!\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "# %pip install pyarrow\n",
    "\n",
    "# (Assure-toi d'avoir import√© ta fonction convert_pluribus_df avant, \n",
    "# ou qu'elle soit d√©finie dans une cellule pr√©c√©dente)\n",
    "# from features.feature_builder import convert_pluribus_df \n",
    "\n",
    "parser = argparse.ArgumentParser(description='Convertir Pluribus DF ‚Üí features')\n",
    "parser.add_argument('--input', type=str, default='pluribus_processed.parquet', # J'ai ajust√© le chemin car tu es d√©j√† dans le dossier data/\n",
    "                    help='Chemin du DataFrame Pluribus')\n",
    "parser.add_argument('--output', type=str, default='pluribus_features.npz',\n",
    "                    help='Chemin de sortie (.npz)')\n",
    "parser.add_argument('--max-rows', type=int, default=None,\n",
    "                    help='Limiter le nombre de lignes')\n",
    "\n",
    "# --- C'EST ICI QUE √áA CHANGE ---\n",
    "# Pour utiliser les valeurs par d√©faut (default=...) :\n",
    "args = parser.parse_args([]) \n",
    "\n",
    "# OU, pour forcer des param√®tres sp√©cifiques comme si tu √©tais en ligne de commande :\n",
    "# args = parser.parse_args(['--max-rows', '1000', '--input', 'mon_fichier.parquet'])\n",
    "# -------------------------------\n",
    "\n",
    "print(f\"üìÇ Input: {args.input}\")\n",
    "print(f\"üìÇ Output: {args.output}\")\n",
    "\n",
    "# Cr√©er le dossier si n√©cessaire (ici '.', car tu es d√©j√† dans data/)\n",
    "Path('.').mkdir(exist_ok=True) \n",
    "\n",
    "# Lancer la conversion (D√©commente la ligne ci-dessous si la fonction est import√©e)\n",
    "X, y = convert_pluribus_df(ml_df, args.output, args.max_rows)\n",
    "\n",
    "print(\"\\nüéâ Conversion termin√©e (Simulation)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f97d0514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, ..., 0, 2, 1], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c984d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52b695f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr√™t √† entra√Æner sur 91444 d√©cisions et 87 features.\n",
      "Taille de l'ensemble d'entra√Ænement : 73155 √©chantillons\n",
      "Taille de l'ensemble de test : 18289 √©chantillons\n",
      "\n",
      "Entra√Ænement du Random Forest... (cela peut prendre un moment)...\n",
      "--- Entra√Ænement termin√© ! ---\n",
      "\n",
      "√âvaluation du mod√®le sur l'ensemble de test...\n",
      "\n",
      "Pr√©cision (Accuracy) : 83.80%\n",
      "\n",
      "--- Rapport de Classification ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FOLD       0.94      0.93      0.94      9663\n",
      "  CHECK/CALL       0.72      0.79      0.75      4927\n",
      "   BET/RAISE       0.73      0.65      0.69      3699\n",
      "\n",
      "    accuracy                           0.84     18289\n",
      "   macro avg       0.80      0.79      0.79     18289\n",
      "weighted avg       0.84      0.84      0.84     18289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# --- PR√âREQUIS ---\n",
    "# Assurez-vous que X_final (vos features) et Y_final (votre cible)\n",
    "# sont disponibles depuis le script pr√©c√©dent.\n",
    "\n",
    "# Pour le rapport final, nous avons besoin des noms de nos actions\n",
    "# (l'inverse de notre 'action_map' pr√©c√©dente)\n",
    "target_names_map = {\n",
    "    0: 'FOLD',\n",
    "    1: 'CHECK/CALL',\n",
    "    2: 'BET/RAISE',\n",
    "}\n",
    "# Obtenir les noms dans le bon ordre\n",
    "unique_actions = np.unique(y)\n",
    "action_labels = [target_names_map[i] for i in unique_actions]\n",
    "\n",
    "print(f\"Pr√™t √† entra√Æner sur {y.shape[0]} d√©cisions et {X.shape[1]} features.\")\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Taille de l'ensemble d'entra√Ænement : {X_train.shape[0]} √©chantillons\")\n",
    "print(f\"Taille de l'ensemble de test : {X_test.shape[0]} √©chantillons\")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=30,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- √âTAPE 3 : Entra√Æner le mod√®le ---\n",
    "print(\"\\nEntra√Ænement du Random Forest... (cela peut prendre un moment)...\")\n",
    "rf_model.fit(X_train, Y_train)\n",
    "print(\"--- Entra√Ænement termin√© ! ---\")\n",
    "\n",
    "# --- √âTAPE 4 : √âvaluer le mod√®le ---\n",
    "print(\"\\n√âvaluation du mod√®le sur l'ensemble de test...\")\n",
    "Y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# A. Pr√©cision simple (Accuracy)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"\\nPr√©cision (Accuracy) : {accuracy * 100:.2f}%\")\n",
    "\n",
    "# B. Rapport d√©taill√© (Beaucoup plus utile !)\n",
    "# Cela montre la performance pour CHAQUE action (Fold, Call, Raise...)\n",
    "print(\"\\n--- Rapport de Classification ---\")\n",
    "print(classification_report(Y_test, Y_pred, target_names=action_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc005416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install imblearn\n",
    "# %pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2488d94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/killianguillaume/Desktop/RL_phase2/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# Le nouveau mod√®le\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eb55cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application de SMOTE termin√©e.\n",
      "Nouveau set d'entra√Ænement (apr√®s SMOTE) : 115950 √©chantillons\n",
      "\n",
      "Nouvelle distribution des classes d'entra√Ænement :\n",
      "{0: 38650, 1: 38650, 2: 38650}\n",
      "\n",
      "Entra√Ænement du mod√®le XGBoost sur les donn√©es SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/killianguillaume/Desktop/RL_phase2/venv/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Entra√Ænement termin√© ! ---\n",
      "\n",
      "√âvaluation du mod√®le XGBoost sur l'ensemble de test (original)...\n",
      "\n",
      "Pr√©cision (Accuracy) : 85.46%\n",
      "\n",
      "--- Rapport de Classification (XGBoost + SMOTE) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FOLD       0.95      0.94      0.95      9663\n",
      "  CHECK/CALL       0.74      0.81      0.78      4927\n",
      "   BET/RAISE       0.75      0.67      0.71      3699\n",
      "\n",
      "    accuracy                           0.85     18289\n",
      "   macro avg       0.82      0.81      0.81     18289\n",
      "weighted avg       0.86      0.85      0.85     18289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "\n",
    "X_train_smote, Y_train_smote = smote.fit_resample(X_train, Y_train)\n",
    "\n",
    "print(\"Application de SMOTE termin√©e.\")\n",
    "print(f\"Nouveau set d'entra√Ænement (apr√®s SMOTE) : {X_train_smote.shape[0]} √©chantillons\")\n",
    "\n",
    "# Regardez la nouvelle distribution (elle sera √©quilibr√©e !)\n",
    "print(\"\\nNouvelle distribution des classes d'entra√Ænement :\")\n",
    "unique, counts = np.unique(Y_train_smote, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "# --- √âTAPE 2 : Cr√©er le mod√®le XGBoost ---\n",
    "# XGBoost a des param√®tres similaires, mais 'eval_metric' est important\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=350,       # 150 arbres s√©quentiels\n",
    "    learning_rate=0.1,      # Vitesse d'apprentissage\n",
    "    max_depth=8,           # Profondeur max (plus profond que RF)\n",
    "    random_state=42,\n",
    "    min_child_weight = 5,\n",
    "    subsample= 0.9,\n",
    "    colsample_bytree= 0.9,\n",
    "    # gamma= 0.6637340904395472,\n",
    "    # reg_alpha= 0.449046849267851,\n",
    "    # reg_lambda= 0.9752487950663815,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,  # Param√®tres techniques\n",
    "    eval_metric='mlogloss'    # M√©trique d'√©valuation pour multi-classes\n",
    ")\n",
    "\n",
    "# --- √âTAPE 3 : Entra√Æner XGBoost sur les donn√©es SMOTE ---\n",
    "print(\"\\nEntra√Ænement du mod√®le XGBoost sur les donn√©es SMOTE...\")\n",
    "xgb_model.fit(X_train_smote, Y_train_smote)\n",
    "print(\"--- Entra√Ænement termin√© ! ---\")\n",
    "\n",
    "# --- √âTAPE 4 : √âvaluer sur les donn√©es de TEST (les vraies !) ---\n",
    "print(\"\\n√âvaluation du mod√®le XGBoost sur l'ensemble de test (original)...\")\n",
    "Y_pred_xgb = xgb_model.predict(X_test) # Pr√©dit sur X_test normal\n",
    "\n",
    "print(f\"\\nPr√©cision (Accuracy) : {accuracy_score(Y_test, Y_pred_xgb) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\n--- Rapport de Classification (XGBoost + SMOTE) ---\")\n",
    "print(classification_report(Y_test, Y_pred_xgb, target_names=action_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d664115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Application de SMOTE...\n",
      "‚úÖ Avant SMOTE: 58524 samples\n",
      "‚úÖ Apr√®s SMOTE: 92760 samples\n"
     ]
    }
   ],
   "source": [
    "X_train_inner, X_val_inner, Y_train_inner, Y_val_inner = train_test_split(\n",
    "    X_train, Y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=Y_train\n",
    ")\n",
    "\n",
    "\n",
    "print(\"üîÑ Application de SMOTE...\")\n",
    "smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "X_train_smote, Y_train_smote = smote.fit_resample(X_train_inner, Y_train_inner)\n",
    "\n",
    "print(f\"‚úÖ Avant SMOTE: {len(Y_train_inner)} samples\")\n",
    "print(f\"‚úÖ Apr√®s SMOTE: {len(Y_train_smote)} samples\")\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_smote, label=Y_train_smote)\n",
    "dval = xgb.DMatrix(X_val_inner, label=Y_val_inner)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Fonction objectif optimis√©e avec XGBoost natif\n",
    "    \n",
    "    Am√©liorations vs ton code:\n",
    "    - Early stopping automatique\n",
    "    - Inf√©rence plus rapide\n",
    "    - Meilleur monitoring\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- Hyperparam√®tres √† optimiser ---\n",
    "    params = {\n",
    "        'objective': 'multi:softprob',  # ‚ö†Ô∏è softprob pour avoir les probabilit√©s\n",
    "        'num_class': 3,  # FOLD, CALL, RAISE\n",
    "        'eval_metric': 'mlogloss',\n",
    "        \n",
    "        # Param√®tres √† optimiser\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "        'subsample': trial.suggest_float('subsample', 0.8, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 1e-8, 5.0, log=True),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 5.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 5.0, log=True),\n",
    "        \n",
    "        # Param√®tres fixes\n",
    "        'seed': 42,\n",
    "        'tree_method': 'hist',  # ‚úÖ Plus rapide que 'auto'\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    # --- Entra√Ænement avec early stopping ---\n",
    "    num_boost_round = trial.suggest_int('n_estimators', 100, 500)\n",
    "    \n",
    "    evals = [(dtrain, 'train'), (dval, 'val')]\n",
    "    \n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=evals,\n",
    "        early_stopping_rounds=50,  # ‚úÖ Stop si pas d'am√©lioration\n",
    "        verbose_eval=False  # Silence pendant Optuna\n",
    "    )\n",
    "    \n",
    "    # --- Pr√©diction sur validation ---\n",
    "    y_pred_proba = model.predict(dval)  # Shape: (n_samples, 3)\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)  # Classes pr√©dites\n",
    "    \n",
    "    # --- Calcul du F1-score macro ---\n",
    "    f1 = f1_score(Y_val_inner, y_pred, average='macro')\n",
    "    \n",
    "    # ‚úÖ Optuna va maximiser ce score\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1be37fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "149199b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"=\"*70)\n",
    "# print(\"OPTIMISATION HYPERPARAM√àTRES - XGBoost + SMOTE avec Optuna\")\n",
    "# print(\"=\"*70)\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "# study = optuna.create_study(\n",
    "#     direction='maximize',\n",
    "#     study_name='xgboost_smote_optimization',\n",
    "#     sampler=optuna.samplers.TPESampler(n_startup_trials=50,seed=42)\n",
    "# )\n",
    "\n",
    "# # Lancer l'optimisation\n",
    "# print(\"\\nüöÄ D√©but de l'optimisation...\")\n",
    "# print(f\"Nombre d'essais pr√©vus : 100\")\n",
    "# print(\"-\"*70)\n",
    "\n",
    "# study.optimize(\n",
    "#     objective,\n",
    "#     n_trials=100,\n",
    "#     show_progress_bar=False,\n",
    "#     n_jobs=1\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f29c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ============================================================================\n",
    "# # AFFICHAGE DES R√âSULTATS\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"R√âSULTATS DE L'OPTIMISATION\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# print(f\"\\n‚úÖ Meilleur score (F1-macro CV) : {study.best_value:.4f}\")\n",
    "# print(f\"üìä Nombre total d'essais : {len(study.trials)}\")\n",
    "\n",
    "\n",
    "# print(\"\\nüèÜ MEILLEURS HYPERPARAM√àTRES TROUV√âS :\")\n",
    "# print(\"-\"*70)\n",
    "# for key, value in study.best_params.items():\n",
    "#     print(f\"  {key:25s} : {value}\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # ENTRA√éNEMENT DU MOD√àLE FINAL AVEC LES MEILLEURS PARAM√àTRES\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*70)\n",
    "# print(\"ENTRA√éNEMENT DU MOD√àLE FINAL\")\n",
    "# print(\"=\"*70)\n",
    "\n",
    "# # Extraction des param√®tres optimaux\n",
    "# best_params = study.best_params.copy()\n",
    "# # Reconvertir avec les meilleurs params\n",
    "# final_params = {\n",
    "#     'objective': 'multi:softprob',\n",
    "#     'num_class': 3,\n",
    "#     'eval_metric': 'mlogloss',\n",
    "#     'max_depth': best_params['max_depth'],\n",
    "#     'learning_rate': best_params['learning_rate'],\n",
    "#     'min_child_weight': best_params['min_child_weight'],\n",
    "#     'subsample': best_params['subsample'],\n",
    "#     'colsample_bytree': best_params['colsample_bytree'],\n",
    "#     'gamma': best_params['gamma'],\n",
    "#     'reg_alpha': best_params['reg_alpha'],\n",
    "#     'reg_lambda': best_params['reg_lambda'],\n",
    "#     'seed': 42,\n",
    "#     'tree_method': 'hist'\n",
    "# }\n",
    "\n",
    "# # Entra√Æner sur TOUTES les donn√©es d'entra√Ænement (avec SMOTE)\n",
    "# final_model = xgb.train(\n",
    "#     final_params,\n",
    "#     dtrain,\n",
    "#     num_boost_round=best_params['n_estimators'],\n",
    "#     evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "#     early_stopping_rounds=50,\n",
    "#     verbose_eval=10\n",
    "# )\n",
    "\n",
    "# print(\"\\nüìä √âvaluation sur le set de validation...\")\n",
    "\n",
    "# # Pr√©dictions\n",
    "# y_pred_proba = final_model.predict(dval)\n",
    "# y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# # Classification report\n",
    "# print(\"\\n\" + classification_report(\n",
    "#     Y_val_inner,\n",
    "#     y_pred,\n",
    "#     target_names=['FOLD', 'CALL', 'RAISE'],\n",
    "#     digits=4\n",
    "# ))\n",
    "\n",
    "\n",
    "\n",
    "# if 'X_test' in locals() and 'Y_test' in locals():\n",
    "#     print(\"\\nüß™ √âvaluation sur le set de TEST...\")\n",
    "    \n",
    "#     dtest = xgb.DMatrix(X_test, label=Y_test)\n",
    "#     y_test_pred_proba = final_model.predict(dtest)\n",
    "#     y_test_pred = np.argmax(y_test_pred_proba, axis=1)\n",
    "    \n",
    "#     print(classification_report(\n",
    "#         Y_test,\n",
    "#         y_test_pred,\n",
    "#         target_names=['FOLD', 'CALL', 'RAISE'],\n",
    "#         digits=4\n",
    "#     ))\n",
    "\n",
    "# print(\"\\n\" + \"=\"*60)\n",
    "# print(\"‚úÖ ENTRA√éNEMENT TERMIN√â\")\n",
    "# print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42e3e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "406221ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "161d7c27",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mb\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa93bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®le sauvegard√© avec succ√®s :\n",
      "üìÅ Chemin : models/xgb/xgb_pluribus_2026-01-29_12-31_fe6426.json\n",
      "üîë ID Unique : fe6426\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import uuid\n",
    "\n",
    "# Supposons que ton mod√®le s'appelle 'model' (ton XGBClassifier entra√Æn√©)\n",
    "\n",
    "def save_model_with_version(model, base_name=\"xgb_pluribus\", save_dir=\"models/xgb\"):\n",
    "    # 1. Cr√©er le dossier s'il n'existe pas\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 2. G√©n√©rer le Timestamp (Ann√©e-Mois-Jour_Heure-Minute)\n",
    "    # Ex: 2023-10-27_15-30\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    \n",
    "    # 3. G√©n√©rer un Hash unique court (6 caract√®res suffisent pour √©viter les collisions)\n",
    "    # Ex: a1b2c3\n",
    "    unique_hash = uuid.uuid4().hex[:6]\n",
    "    \n",
    "    # 4. Construire le nom final\n",
    "    # Ex: xgb_pluribus_2023-10-27_15-30_a1b2c3.json\n",
    "    filename = f\"{base_name}_{timestamp}_{unique_hash}.json\"\n",
    "    full_path = os.path.join(save_dir, filename)\n",
    "    \n",
    "    # 5. Sauvegarder\n",
    "    # Note: .save_model() est la m√©thode native XGBoost (compatible avec ton agent C++/Python)\n",
    "    model.save_model(full_path)\n",
    "    \n",
    "    print(f\"‚úÖ Mod√®le sauvegard√© avec succ√®s :\")\n",
    "    print(f\"üìÅ Chemin : {full_path}\")\n",
    "    print(f\"üîë ID Unique : {unique_hash}\")\n",
    "    \n",
    "    return full_path\n",
    "\n",
    "# --- UTILISATION ---\n",
    "# Une fois ton fit termin√© :\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# Tu appelles la fonction\n",
    "saved_path = save_model_with_version(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cef614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° G√©n√©ration des visualisations Optuna...\n",
      "  ‚ö†Ô∏è Impossible de g√©n√©rer les visualisations : Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.\n",
      "\n",
      "======================================================================\n",
      "‚ú® OPTIMISATION TERMIN√âE !\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Mod√®le sauvegard√© : xgb_pluribus_v1.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüí° G√©n√©ration des visualisations Optuna...\")\n",
    "\n",
    "\n",
    "try:\n",
    "    # Historique d'optimisation\n",
    "    fig1 = plot_optimization_history(study)\n",
    "    fig1.show()\n",
    "    print(\"  ‚úÖ Sauvegard√© : optuna_optimization_history.html\")\n",
    "\n",
    "    # Importance des param√®tres\n",
    "    fig2 = plot_param_importances(study)\n",
    "    fig2.show()\n",
    "    print(\"  ‚úÖ Sauvegard√© : optuna_param_importances.html\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö†Ô∏è Impossible de g√©n√©rer les visualisations : {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚ú® OPTIMISATION TERMIN√âE !\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ============================================================================\n",
    "# SAUVEGARDE DU MOD√àLE (optionnel)\n",
    "# ============================================================================\n",
    "# D√©commentez pour sauvegarder le mod√®le\n",
    "import joblib\n",
    "joblib.dump(xgb_model, 'xgb_pluribus_v1.pkl')\n",
    "print(\"\\nüíæ Mod√®le sauvegard√© : xgb_pluribus_v1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c613d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
